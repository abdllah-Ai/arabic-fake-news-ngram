# Arabic Fake News Analysis using N-Grams

This project performs text preprocessing and N-Gram analysis on Arabic news claims to identify the most frequent patterns in real vs. fake news.

## ğŸ” Objective

To compare linguistic patterns between fake and real Arabic news using:
- Unigrams
- Bigrams
- Trigrams
- Word Clouds
- Frequency Bar Charts

## ğŸ“ Dataset

- **Source**: `AraFacts.csv`
- **Columns Used**: `claim`, `normalized_label`
- **Labels Converted**: 
  - `True` â†’ Real
  - `False`, `Partly-false` â†’ Fake

## ğŸ› ï¸ Features

- Arabic text normalization
- Stop word removal
- Tokenization
- N-gram extraction
- Visualization using matplotlib and wordcloud

## ğŸ“¦ Requirements

Install the required packages using:

```bash
pip install -r requirements.txt
```

## â–¶ï¸ How to Run

Make sure `AraFacts.csv` is in the same directory, then:

```bash
python your_script_name.py
```

## ğŸ“Š Output

- Top 10 Unigrams, Bigrams, and Trigrams for each category (Fake, Real)
- Word Clouds per category
- Horizontal bar charts for frequency comparison

## ğŸ“Œ Notes

- Make sure to download NLTK stopwords beforehand (done automatically in script).
- Font used for Arabic wordcloud rendering: `arial`
